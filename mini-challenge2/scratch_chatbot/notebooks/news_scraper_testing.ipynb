{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple SRF News Json File Extractor\n",
    "\n",
    "Dieses Notebook dient als Experimentierfeld für die Extraktion von Daten aus dem SRF News zu einem JSON-File.   \n",
    "Die Funktionen werden in der Datei `srf_news.py` gespeichert und können dann in einem anderen Notebook importiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "\n",
    "# define url and topic\n",
    "url = \"https://www.srf.ch\"\n",
    "topic = \"news\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resultcenter', 'www.srf.ch', 'www.rts.ch', 'wirtschaft', 'www.rtr.ch', 'gesundheit', 'startseite', 'literatur', 'www.rsi.ch', 'www.swissinfo.ch', 'woerterbuch', 'www.radioswisspop.ch', 'meteo-stories', 'dialog', 'www.srgssr.ch', 'live', 'decodar-nossa-cultura', 'jobs.srf.ch', 'musik', 'ski-alpin', 'www.radioswissclassic.ch', 'website-und-apps', 'radio', 'kunst', 'arbeitsrecht', 'mehr-sport', 'kassensturz-espresso', 'themen', 'tv', 'www.radioswissjazz.ch', 'gesellschaft', 'fussball', 'eishockey', 'wetter', 'video', 'schweiz', 'school', 'tennis', 'international'}\n"
     ]
    }
   ],
   "source": [
    "def extract_possible_topics(url):\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find all anchor tags (a) with an 'href' attribute\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "        # Initialize a set to store unique topics\n",
    "        possible_topics = set()\n",
    "\n",
    "        # Extract and categorize topics from the URLs\n",
    "        for link in links:\n",
    "            formatted_url = urljoin(url, link[\"href\"])\n",
    "            # Extract potential topic keywords from the URL\n",
    "            topics = re.findall(r'/([^/]+)/', formatted_url)\n",
    "            for topic in topics:\n",
    "                possible_topics.add(topic)\n",
    "\n",
    "        return possible_topics\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# call function\n",
    "print(extract_possible_topics(\"https://www.srf.ch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Topic all Link Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.srf.ch/sport', 'https://www.srf.ch/sport', 'https://www.srf.ch/sport/resultcenter/results#/live/ski/1792634', 'https://www.srf.ch/sport', 'https://www.srf.ch/sport/fussball/europa-league/kehrauspartie-fuer-lugano-servette-kann-slavia-nur-noch-den-gruppensieg-streitig-machen', 'https://www.srf.ch/sport/fussball/champions-league/abschluss-der-cl-gruppenphase-ein-rueckblick-zwischen-1-und-10-000', 'https://www.srf.ch/sport/ski-alpin/weltcup-frauen/news-aus-dem-skisport-kein-frauen-training-am-donnerstag-in-val-d-isere', 'https://www.srf.ch/sport/eishockey/nationalmannschaft/nl-topskorer-vor-heimturnier-thuerkauf-wir-wissen-was-auf-dem-spiel-steht', 'https://www.srf.ch/sport/mehr-sport/rad/news-aus-dem-radsport-tour-de-suisse-2024-in-rueschlikon-ambri-cari-und-blatten', 'https://www.srf.ch/sport/fussball/champions-league/umfrage-nach-gruppenphase-wer-hat-s-am-besten-gemacht-waehlen-sie-den-schoensten-cl-treffer', 'https://www.srf.ch/sport/mehr-sport/basketball/aufregung-in-der-nba-antetokounmpo-glaenzt-mit-64-punkten-und-sucht-danach-den-ball', 'https://www.srf.ch/sport/eishockey/nhl/unauffaellige-nhl-schweizer-new-jersey-schafft-mal-wieder-die-wende', 'https://www.srf.ch/sport/fussball/super-league/winterthur-siegt-im-derby-2-1-burkart-schockt-den-fcz-in-der-93-minute', 'https://www.srf.ch/sport/fussball/champions-league/1-2-bei-rb-leipzig-wilde-minuten-nach-der-pause-yb-verliert-zum-cl-abschluss', 'https://www.srf.ch/sport/fussball/champions-league/round-up-champions-league-psg-mueht-sich-in-den-achtelfinal-auch-porto-loest-ticket', 'https://www.srf.ch/sport/mehr-sport/biathlon/vor-heim-weltcup-im-hoch-haecki-gross-will-es-auch-in-lenzerheide-wissen', 'https://www.srf.ch/sport/eishockey/frauen-nationalteam/5-laenderturnier-in-falun-tschechien-wieder-zu-stark-frauen-nati-verliert-zum-start', 'https://www.srf.ch/sport/fussball/internationale-ligen/internationale-fussball-news-ter-stegen-faellt-nach-ruecken-op-weiter-aus-auch-dybala-out', 'https://www.srf.ch/sport/mehr-sport/biathlon/premiere-in-lenzerheide-biathlon-weltcup-kommt-zum-1-mal-in-die-schweiz', 'https://www.srf.ch/sport/ski-alpin/news-aus-dem-skisport-voller-fokus-auf-die-rennen-kein-abschlusstraining-in-groeden', 'https://www.srf.ch/sport/fussball/champions-league/franzosen-bei-bvb-unter-druck-psg-muss-liefern-sonst-droht-das-erste-cl-out-seit-2011', 'https://www.srf.ch/sport/tennis/atp-tour/australier-beisst-auf-zaehne-kyrgios-ich-moechte-nicht-mehr-spielen', 'https://www.srf.ch/sport', 'https://www.srf.ch/sport']\n"
     ]
    }
   ],
   "source": [
    "def scrape_srf_links(url, topic):\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find all anchor tags (a) with an 'href' attribute\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "        # Initialize a list to store links for the specified topic\n",
    "        topic_links = []\n",
    "\n",
    "        # Categorize and format the URLs into the list for the specified topic\n",
    "        for link in links:\n",
    "            formatted_url = urljoin(url, link[\"href\"])\n",
    "            if f\"/{topic}\" in formatted_url:\n",
    "                topic_links.append(formatted_url)\n",
    "\n",
    "        return topic_links\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# call function\n",
    "print(scrape_srf_links(\"https://www.srf.ch\", \"sport\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Combine Topic Extraction and Link Extraction into one funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resultcenter', 'www.srf.ch', 'www.rts.ch', 'wirtschaft', 'www.rtr.ch', 'gesundheit', 'startseite', 'literatur', 'www.rsi.ch', 'www.swissinfo.ch', 'woerterbuch', 'www.radioswisspop.ch', 'meteo-stories', 'dialog', 'www.srgssr.ch', 'live', 'decodar-nossa-cultura', 'jobs.srf.ch', 'musik', 'ski-alpin', 'www.radioswissclassic.ch', 'website-und-apps', 'radio', 'kunst', 'arbeitsrecht', 'mehr-sport', 'kassensturz-espresso', 'themen', 'tv', 'www.radioswissjazz.ch', 'gesellschaft', 'fussball', 'eishockey', 'wetter', 'video', 'schweiz', 'school', 'tennis', 'international']\n",
      "['https://www.srf.ch/sport', 'https://www.srf.ch/sport', 'https://www.srf.ch/sport/resultcenter/results#/live/ski/1792634', 'https://www.srf.ch/sport', 'https://www.srf.ch/sport/fussball/europa-league/kehrauspartie-fuer-lugano-servette-kann-slavia-nur-noch-den-gruppensieg-streitig-machen', 'https://www.srf.ch/sport/fussball/champions-league/abschluss-der-cl-gruppenphase-ein-rueckblick-zwischen-1-und-10-000', 'https://www.srf.ch/sport/ski-alpin/weltcup-frauen/news-aus-dem-skisport-kein-frauen-training-am-donnerstag-in-val-d-isere', 'https://www.srf.ch/sport/eishockey/nationalmannschaft/nl-topskorer-vor-heimturnier-thuerkauf-wir-wissen-was-auf-dem-spiel-steht', 'https://www.srf.ch/sport/mehr-sport/rad/news-aus-dem-radsport-tour-de-suisse-2024-in-rueschlikon-ambri-cari-und-blatten', 'https://www.srf.ch/sport/fussball/champions-league/umfrage-nach-gruppenphase-wer-hat-s-am-besten-gemacht-waehlen-sie-den-schoensten-cl-treffer', 'https://www.srf.ch/sport/mehr-sport/basketball/aufregung-in-der-nba-antetokounmpo-glaenzt-mit-64-punkten-und-sucht-danach-den-ball', 'https://www.srf.ch/sport/eishockey/nhl/unauffaellige-nhl-schweizer-new-jersey-schafft-mal-wieder-die-wende', 'https://www.srf.ch/sport/fussball/super-league/winterthur-siegt-im-derby-2-1-burkart-schockt-den-fcz-in-der-93-minute', 'https://www.srf.ch/sport/fussball/champions-league/1-2-bei-rb-leipzig-wilde-minuten-nach-der-pause-yb-verliert-zum-cl-abschluss', 'https://www.srf.ch/sport/fussball/champions-league/round-up-champions-league-psg-mueht-sich-in-den-achtelfinal-auch-porto-loest-ticket', 'https://www.srf.ch/sport/mehr-sport/biathlon/vor-heim-weltcup-im-hoch-haecki-gross-will-es-auch-in-lenzerheide-wissen', 'https://www.srf.ch/sport/eishockey/frauen-nationalteam/5-laenderturnier-in-falun-tschechien-wieder-zu-stark-frauen-nati-verliert-zum-start', 'https://www.srf.ch/sport/fussball/internationale-ligen/internationale-fussball-news-ter-stegen-faellt-nach-ruecken-op-weiter-aus-auch-dybala-out', 'https://www.srf.ch/sport/mehr-sport/biathlon/premiere-in-lenzerheide-biathlon-weltcup-kommt-zum-1-mal-in-die-schweiz', 'https://www.srf.ch/sport/ski-alpin/news-aus-dem-skisport-voller-fokus-auf-die-rennen-kein-abschlusstraining-in-groeden', 'https://www.srf.ch/sport/fussball/champions-league/franzosen-bei-bvb-unter-druck-psg-muss-liefern-sonst-droht-das-erste-cl-out-seit-2011', 'https://www.srf.ch/sport/tennis/atp-tour/australier-beisst-auf-zaehne-kyrgios-ich-moechte-nicht-mehr-spielen', 'https://www.srf.ch/sport', 'https://www.srf.ch/sport']\n"
     ]
    }
   ],
   "source": [
    "def scrape_srf_links(url, topic=None):\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find all anchor tags (a) with an 'href' attribute\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "        # Initialize a list to store links for the specified topic\n",
    "        topic_links = []\n",
    "\n",
    "        # Initialize a set to store unique topics\n",
    "        possible_topics = set()\n",
    "\n",
    "        # Categorize and format the URLs into the list for the specified topic\n",
    "        for link in links:\n",
    "            formatted_url = urljoin(url, link[\"href\"])\n",
    "            topics = re.findall(r'/([^/]+)/', formatted_url)\n",
    "            for t in topics:\n",
    "                possible_topics.add(t)\n",
    "            if topic and f\"/{topic}\" in formatted_url:\n",
    "                topic_links.append(formatted_url)\n",
    "\n",
    "        if topic:\n",
    "            return topic_links\n",
    "        else:\n",
    "            return possible_topics\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# To get all possible topics\n",
    "print(list(scrape_srf_links(\"https://www.srf.ch\")))\n",
    "\n",
    "# To get links related to a specific topic (e.g., \"sport\")\n",
    "print(scrape_srf_links(\"https://www.srf.ch\", \"sport\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Extract all Topics and Links export to Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file 'data/news.json' created successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_json_for_intent(topic, filename, data_directory=\"data/\"):\n",
    "    # Call the existing function to scrape links\n",
    "    topic_links = scrape_srf_links(url, topic=\"news\")\n",
    "\n",
    "    # Check if links were successfully retrieved\n",
    "    if topic_links:\n",
    "        # Prepare the JSON structure\n",
    "        data = {\n",
    "            \"intents\": [\n",
    "                {\n",
    "                    \"tag\": topic.replace(\"_\", \" \"),\n",
    "                    \"patterns\": [f\"Get me the {topic.replace('_', ' ')}\"],\n",
    "                    \"responses\": []\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Add a response for each link\n",
    "        for link in topic_links:\n",
    "            response_variations = [\n",
    "                f\"Here is a {topic.replace('_', ' ')}: {link}\",\n",
    "                f\"Here's some {topic.replace('_', ' ')} for you: {link}\",\n",
    "                f\"Check out this {topic.replace('_', ' ')}: {link}\",\n",
    "                f\"Here's the latest {topic.replace('_', ' ')}: {link}\",\n",
    "                f\"Sure, here's a {topic.replace('_', ' ')}: {link}\",\n",
    "                f\"{topic.replace('_', ' ')} coming right up: {link}\",\n",
    "                f\"Here you go, the {topic.replace('_', ' ')} you requested: {link}\",\n",
    "                f\"Enjoy this {topic.replace('_', ' ')}: {link}\"\n",
    "            ]\n",
    "            response = random.choice(response_variations)\n",
    "            data[\"intents\"][0][\"responses\"].append(response)\n",
    "\n",
    "        # Specify the full path to the JSON file\n",
    "        full_path = os.path.join(data_directory, filename)\n",
    "\n",
    "        # Write the data to the JSON file\n",
    "        with open(full_path, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "\n",
    "        print(f\"JSON file '{full_path}' created successfully.\")\n",
    "    else:\n",
    "        print(\"No links found for the topic. JSON file not created.\")\n",
    "\n",
    "# call function\n",
    "create_json_for_intent(topic=\"news\", filename=\"news.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Extract all Topics and Links export to Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file 'data/resultcenter.json' created successfully for resultcenter news.\n",
      "JSON file 'data/www.srf.ch.json' created successfully for www.srf.ch news.\n",
      "JSON file 'data/www.rts.ch.json' created successfully for www.rts.ch news.\n",
      "JSON file 'data/wirtschaft.json' created successfully for wirtschaft news.\n",
      "JSON file 'data/www.rtr.ch.json' created successfully for www.rtr.ch news.\n",
      "JSON file 'data/gesundheit.json' created successfully for gesundheit news.\n",
      "JSON file 'data/startseite.json' created successfully for startseite news.\n",
      "JSON file 'data/literatur.json' created successfully for literatur news.\n",
      "JSON file 'data/www.rsi.ch.json' created successfully for www.rsi.ch news.\n",
      "JSON file 'data/www.swissinfo.ch.json' created successfully for www.swissinfo.ch news.\n",
      "JSON file 'data/woerterbuch.json' created successfully for woerterbuch news.\n",
      "JSON file 'data/www.radioswisspop.ch.json' created successfully for www.radioswisspop.ch news.\n",
      "JSON file 'data/meteo-stories.json' created successfully for meteo-stories news.\n",
      "JSON file 'data/dialog.json' created successfully for dialog news.\n",
      "JSON file 'data/www.srgssr.ch.json' created successfully for www.srgssr.ch news.\n",
      "JSON file 'data/live.json' created successfully for live news.\n",
      "JSON file 'data/decodar-nossa-cultura.json' created successfully for decodar-nossa-cultura news.\n",
      "JSON file 'data/jobs.srf.ch.json' created successfully for jobs.srf.ch news.\n",
      "JSON file 'data/musik.json' created successfully for musik news.\n",
      "JSON file 'data/ski-alpin.json' created successfully for ski-alpin news.\n",
      "JSON file 'data/www.radioswissclassic.ch.json' created successfully for www.radioswissclassic.ch news.\n",
      "JSON file 'data/website-und-apps.json' created successfully for website-und-apps news.\n",
      "JSON file 'data/radio.json' created successfully for radio news.\n",
      "JSON file 'data/kunst.json' created successfully for kunst news.\n",
      "JSON file 'data/arbeitsrecht.json' created successfully for arbeitsrecht news.\n",
      "JSON file 'data/mehr-sport.json' created successfully for mehr-sport news.\n",
      "JSON file 'data/kassensturz-espresso.json' created successfully for kassensturz-espresso news.\n",
      "JSON file 'data/themen.json' created successfully for themen news.\n",
      "JSON file 'data/tv.json' created successfully for tv news.\n",
      "JSON file 'data/www.radioswissjazz.ch.json' created successfully for www.radioswissjazz.ch news.\n",
      "JSON file 'data/gesellschaft.json' created successfully for gesellschaft news.\n",
      "JSON file 'data/fussball.json' created successfully for fussball news.\n",
      "JSON file 'data/eishockey.json' created successfully for eishockey news.\n",
      "JSON file 'data/wetter.json' created successfully for wetter news.\n",
      "JSON file 'data/video.json' created successfully for video news.\n",
      "JSON file 'data/schweiz.json' created successfully for schweiz news.\n",
      "JSON file 'data/school.json' created successfully for school news.\n",
      "JSON file 'data/tennis.json' created successfully for tennis news.\n",
      "JSON file 'data/international.json' created successfully for international news.\n"
     ]
    }
   ],
   "source": [
    "def create_json_for_topics(topics, data_directory=\"data/\"):\n",
    "    for topic in topics:\n",
    "        # Call the existing function to scrape links\n",
    "        topic_links = scrape_srf_links(\"https://www.srf.ch\", topic)\n",
    "\n",
    "        # Check if links were successfully retrieved\n",
    "        if topic_links:\n",
    "            # Prepare the JSON structure\n",
    "            data = {\n",
    "                \"intents\": [\n",
    "                    {\n",
    "                        \"tag\": topic.replace(\"_\", \" \"),\n",
    "                        \"patterns\": [f\"Get me {topic.replace('_', ' ')} news\"],\n",
    "                        \"responses\": []\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Add a response for each link\n",
    "            for link in topic_links:\n",
    "                response_variations = [\n",
    "                    f\"Here is a {topic.replace('_', ' ')} news article: {link}\",\n",
    "                    f\"Here's some {topic.replace('_', ' ')} news for you: {link}\",\n",
    "                    f\"Check out this {topic.replace('_', ' ')} news: {link}\",\n",
    "                    f\"Here's the latest {topic.replace('_', ' ')} news: {link}\",\n",
    "                    f\"Sure, here's a {topic.replace('_', ' ')} news link: {link}\",\n",
    "                    f\"{topic.replace('_', ' ')} news coming right up: {link}\",\n",
    "                    f\"Here you go, the {topic.replace('_', ' ')} news you requested: {link}\",\n",
    "                    f\"Enjoy this {topic.replace('_', ' ')} news article: {link}\"\n",
    "                ]\n",
    "                response = random.choice(response_variations)\n",
    "                data[\"intents\"][0][\"responses\"].append(response)\n",
    "\n",
    "            # Specify the full path to the JSON file\n",
    "            filename = f\"{topic}.json\"\n",
    "            full_path = os.path.join(data_directory, filename)\n",
    "\n",
    "            # Write the data to the JSON file\n",
    "            with open(full_path, 'w') as json_file:\n",
    "                json.dump(data, json_file, indent=4)\n",
    "\n",
    "            print(f\"JSON file '{full_path}' created successfully for {topic} news.\")\n",
    "        else:\n",
    "            print(f\"No links found for the topic {topic}. JSON file not created.\")\n",
    "\n",
    "# List of topics you want to create JSON files for\n",
    "topics_list = (list(scrape_srf_links(\"https://www.srf.ch\")))\n",
    "\n",
    "# Call the function to create JSON files for the specified topics\n",
    "create_json_for_topics(topics_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Extract all Topics and Links export to One Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined JSON file 'data/intents_news.json' created successfully for all topics.\n"
     ]
    }
   ],
   "source": [
    "def create_combined_json_for_topics(topics, data_directory=\"data/\"):\n",
    "    # Initialize a dictionary to store data for all topics\n",
    "    combined_data = {\n",
    "        \"intents\": []\n",
    "    }\n",
    "\n",
    "    for topic in topics:\n",
    "        # Call the existing function to scrape links\n",
    "        topic_links = scrape_srf_links(\"https://www.srf.ch\", topic)\n",
    "\n",
    "        # Check if links were successfully retrieved\n",
    "        if topic_links:\n",
    "            # Prepare the JSON structure for the current topic\n",
    "            topic_data = {\n",
    "                \"tag\": topic.replace(\"_\", \" \"),\n",
    "                \"patterns\": [\n",
    "                    f\"Get me the latest {topic.replace('_', ' ')}\",\n",
    "                    f\"Tell me about {topic.replace('_', ' ')}\",\n",
    "                    f\"What's happening in {topic.replace('_', ' ')}\",\n",
    "                    f\"Give me updates on {topic.replace('_', ' ')}\",\n",
    "                    f\"I'm interested in {topic.replace('_', ' ')}\",\n",
    "                    f\"Can you provide {topic.replace('_', ' ')} \",\n",
    "                    f\"Tell me more about {topic.replace('_', ' ')}\",\n",
    "                    f\"Share {topic.replace('_', ' ')}\",\n",
    "                    f\"{topic.replace('_', ' ')}\",\n",
    "                ],\n",
    "                \"responses\": []\n",
    "            }\n",
    "\n",
    "            # Add a response for each link\n",
    "            for link in topic_links:\n",
    "                response_variations = [\n",
    "                    f\"Here is a {topic.replace('_', ' ')} news article: {link}\",\n",
    "                    f\"Here's some {topic.replace('_', ' ')} news for you: {link}\",\n",
    "                    f\"Check out this {topic.replace('_', ' ')} news: {link}\",\n",
    "                    f\"Here's the latest {topic.replace('_', ' ')} news: {link}\",\n",
    "                    f\"Sure, here's a {topic.replace('_', ' ')} news link: {link}\",\n",
    "                    f\"{topic.replace('_', ' ')} news coming right up: {link}\",\n",
    "                    f\"Here you go, the {topic.replace('_', ' ')} news you requested: {link}\",\n",
    "                    f\"Enjoy this {topic.replace('_', ' ')} news article: {link}\"\n",
    "                ]\n",
    "                response = random.choice(response_variations)\n",
    "                topic_data[\"responses\"].append(response)\n",
    "\n",
    "            # Add the data for the current topic to the combined_data\n",
    "            combined_data[\"intents\"].append(topic_data)\n",
    "        else:\n",
    "            print(f\"No links found for the topic {topic}. Skipping.\")\n",
    "\n",
    "    # Specify the full path to the combined JSON file\n",
    "    combined_filename = \"intents_news.json\"\n",
    "    combined_full_path = os.path.join(data_directory, combined_filename)\n",
    "\n",
    "    # Write the combined data to the JSON file\n",
    "    with open(combined_full_path, 'w') as json_file:\n",
    "        json.dump(combined_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Combined JSON file '{combined_full_path}' created successfully for all topics.\")\n",
    "\n",
    "topics_list = (list(scrape_srf_links(\"https://www.srf.ch\")))\n",
    "\n",
    "create_combined_json_for_topics(topics_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratchbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
